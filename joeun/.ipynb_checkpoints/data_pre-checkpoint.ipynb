{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377c7a05-2360-401b-b4b6-854120a1a957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 03:13:24.817099: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.image import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b4b03-6c17-472a-8cd5-b153f41fdc5b",
   "metadata": {},
   "source": [
    "# 데이터 훑어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33c13dab-d393-4793-a353-bbf1d4ae278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일 경로\n",
    "fer2013_path = '/data/face1/fer/fer2013/fer2013.csv'\n",
    "\n",
    "# CSV 파일 읽기\n",
    "data = pd.read_csv(fer2013_path)\n",
    "\n",
    "# 데이터 확인\n",
    "print(data.head())  # 상위 5개 행 출력\n",
    "print(data.info())  # 데이터 정보 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e9e1944-847b-4e5b-b364-14d6a0efc202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage 열의 고유 값: ['Training' 'PublicTest' 'PrivateTest']\n"
     ]
    }
   ],
   "source": [
    "# Usage 열의 값 종류 확인\n",
    "usage_values = data['Usage'].unique()\n",
    "print(\"Usage 열의 고유 값:\", usage_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58dddc1b-9897-490d-b557-f5a22bc5f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감정별 데이터 개수\n",
      "emotion\n",
      "Angry       4953\n",
      "Disgust      547\n",
      "Fear        5121\n",
      "Happy       8989\n",
      "Sad         6077\n",
      "Surprise    4002\n",
      "Neutral     6198\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 감정 라벨 정의\n",
    "emotion_labels = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "\n",
    "# emotion 값별 데이터 개수 세기\n",
    "emotion_counts = data['emotion'].value_counts().sort_index()  # 감정별 데이터 개수\n",
    "emotion_counts.index = emotion_counts.index.map(emotion_labels)  # 숫자 라벨을 감정 이름으로 매핑\n",
    "\n",
    "# 출력\n",
    "print(\"감정별 데이터 개수\")\n",
    "print(emotion_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f718d-a1a7-4ce6-90de-5384c1ce0893",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "1. SMOTE\n",
    "2. 데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0bb207-dc4a-4636-bc7b-3bc97cd8e8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 이미지 전처리 함수\n",
    "# def preprocess_pixels(pixel_data):\n",
    "#   images = []\n",
    "#   for i in range(len(pixel_data)):\n",
    "#     img = np.fromstring(pixel_data[i], dtype='int', sep=' ')\n",
    "#     img = img.reshape(48,48,1)\n",
    "#     images.append(img)\n",
    "\n",
    "#   X = np.array(images)\n",
    "\n",
    "#   return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0855be1-778a-41fd-94ce-ce338a3cce54",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data['pixels']  # 픽셀 데이터 (문자열 형태)\n",
    "y = data['emotion']  # 감정 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d77e20-2372-401b-bc68-c69ce1556fcb",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6261fded-a7bd-49c4-b151-1d163652a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 벡터 형태로 변환 (SMOTE를 위해)\n",
    "X = []\n",
    "for i in range(len(X_raw)):\n",
    "    img = np.fromstring(X_raw[i], dtype='int', sep=' ')  # 문자열 -> 숫자 배열\n",
    "    X.append(img)\n",
    "X = np.array(X)  # (샘플 수, 2304) 형태\n",
    "y = np.array(y)  # 라벨도 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "747ee4d3-aaba-42c5-9593-19ba0fcc9788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a99cf936-bf7b-44be-8c80-2351d638a953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: [4953  547 5121 8989 6077 4002 6198]\n",
      "After SMOTE: [8989 8989 8989 8989 8989 8989 8989]\n"
     ]
    }
   ],
   "source": [
    "# SMOTE 결과 확인\n",
    "print(\"Before SMOTE:\", np.bincount(y))\n",
    "print(\"After SMOTE:\", np.bincount(y_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff7aeb4-0d2f-470a-b0be-dac010a21d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE로 생성된 데이터를 다시 48x48 이미지 형태로 변환\n",
    "X_smote_images = []\n",
    "for i in range(len(X_smote)):\n",
    "    img = X_smote[i].reshape(48, 48, 1)  # 48x48 크기로 재구성\n",
    "    X_smote_images.append(img)\n",
    "X_smote_images = np.array(X_smote_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75c7a75e-5fb4-4500-95ce-2db5e073e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# 라벨을 One-hot Encoding\n",
    "num_classes = len(np.unique(y_smote))  # 클래스 개수\n",
    "y_smote_onehot = to_categorical(y_smote, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ee15d-a443-4a15-8039-1f09d1e5213d",
   "metadata": {},
   "source": [
    "## Data Argumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dbae13e-f0ab-444c-acc2-01b0e93212da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강 설정\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,         # 최대 10도 회전\n",
    "    width_shift_range=0.1,     # 가로 이동 10%\n",
    "    height_shift_range=0.1,    # 세로 이동 10%\n",
    "    zoom_range=0.1,            # 확대/축소 10%\n",
    "    horizontal_flip=True,      # 좌우 반전\n",
    "    brightness_range=[0.8, 1.2], # 밝기 조정\n",
    "    fill_mode='nearest'        # 빈 공간을 채우는 방식\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1debd292-dac7-404a-9b80-421c494c4d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강된 데이터를 저장할 배열\n",
    "X_augmented = []\n",
    "y_augmented = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b70123-3ec8-4dfd-816e-34660ad3157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_smote_images)):\n",
    "    img = X_smote_images[i]  # 이미지 데이터\n",
    "    label = y_smote[i]       # 라벨\n",
    "\n",
    "    # 이미지를 증강하고 추가\n",
    "    img = img.reshape((1, 48, 48, 1))  # (배치 크기, 48, 48, 1)로 변환\n",
    "    for batch in datagen.flow(img, batch_size=1):\n",
    "        X_augmented.append(batch[0])  # 증강된 이미지 추가\n",
    "        y_augmented.append(label)     # 라벨 추가\n",
    "        if len(X_augmented) >= len(X_smote_images):  # 원하는 증강 개수만큼 생성\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321c570-e646-4835-aa41-8b7332ff070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 증강된 데이터를 배열로 변환\n",
    "X_augmented = np.array(X_augmented)\n",
    "y_augmented = np.array(y_augmented)\n",
    "\n",
    "# Grayscale 데이터를 RGB로 변환 (채널 복제)\n",
    "# X_augmented_rgb = np.repeat(X_augmented, 3, axis=-1)  # (48, 48, 1) -> (48, 48, 3)\n",
    "\n",
    "# # 이미지를 (224, 224, 3)으로 리사이즈\n",
    "# X_augmented_resized = np.array([resize(img, (224, 224)).numpy() for img in X_augmented_rgb])\n",
    "\n",
    "# # 데이터 크기 확인\n",
    "# print(\"증강된 데이터 크기 (RGB, Resized):\", X_augmented_resized.shape)\n",
    "# print(\"증강된 라벨 크기:\", y_augmented.shape)\n",
    "\n",
    "print(\"증강된 데이터 크기:\", X_augmented.shape)\n",
    "print(\"증강된 라벨 크기:\", y_augmented.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8af50b-7cd6-44d0-b432-5f1174dcb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Numpy 배열로 저장\n",
    "# np.save('X_augmented.npy', X_augmented)  # 증강된 데이터 저장\n",
    "# np.save('y_augmented.npy', y_augmented)  # 라벨 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72b341-ad22-460d-aab4-be8cbe1f99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angry_path = '/data/face1/train/angry/Training_99982465.jpg'\n",
    "# disgust_path = '/data/face1/train/disgust/Training_11550217.jpg'\n",
    "# fear_path = '/data/face1/train/fear/Training_10126156.jpg'\n",
    "# happy_path = '/data/face1/train/happy/Training_10019449.jpg'\n",
    "# sad_path = '/data/face1/train/sad/Training_10031481.jpg'\n",
    "# surprise_path = '/data/face1/train/surprise/Training_1002457.jpg'\n",
    "# neutral_path = '/data/face1/train/neutral/Training_10078021.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b999fa-15b3-4b60-be90-7803472edad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "# img = mpimg.imread(angry_path)\n",
    "\n",
    "# # 그레이스케일 변환 (RGB 평균값 사용)\n",
    "# if len(img.shape) == 3:  # RGB 이미지인지 확인\n",
    "#     img_gray = np.mean(img, axis=2)  # RGB 채널 평균값으로 변환\n",
    "# else:\n",
    "#     img_gray = img  # 이미 그레이스케일인 경우 그대로 사용\n",
    "\n",
    "# # 이미지 표시\n",
    "# plt.imshow(img_gray, cmap='gray')  # cmap='gray'로 설정\n",
    "# plt.axis('off')  # 축 숨기기\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9945f64-df0d-4ee0-8abe-029b1ca25237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
